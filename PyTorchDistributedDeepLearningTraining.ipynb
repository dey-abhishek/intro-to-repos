{"cells":[{"cell_type":"markdown","source":["# Distributed deep learning training using PyTorch with HorovodRunner for MNIST\n\nThis notebook illustrates the use of HorovodRunner for distributed training using PyTorch. \nIt first shows how to train a model on a single node, and then shows how to adapt the code using HorovodRunner for distributed training. \nThe notebook runs on both CPU and GPU clusters.\n\n## Setup Requirements\nDatabricks Runtime 7.6 ML or above (choose either CPU or GPU clusters). Torch and its related packages and Horovod are preinstalled with this runtime.\nHorovodRunner is designed to improve model training performance on clusters with multiple workers, but multiple workers are not required to run this notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1c9a479-ea20-4f49-b3e7-5a67635122c9"}}},{"cell_type":"markdown","source":["## Set up checkpoint location\nThe next cell creates a directory for saved checkpoint models. Databricks recommends saving training data under `dbfs:/ml`, which maps to `file:/dbfs/ml` on driver and worker nodes."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b8c482f-e7b8-4dfe-8d75-07ab5b3b1ea2"}}},{"cell_type":"code","source":["PYTORCH_DIR = '/dbfs/ml/horovod_pytorch'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"312af54a-9184-466f-b1c7-419a10153c3d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Prepare single-node code\n\nFirst, create single-node PyTorch code. This is modified from the [Horovod PyTorch MNIST Example](https://github.com/horovod/horovod/blob/master/examples/pytorch/pytorch_mnist.py)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82f989bb-52a9-4871-adc2-6a5dea50d69c"}}},{"cell_type":"markdown","source":["### Define a simple convolutional network"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76eb87ea-fcd1-48bc-bfaa-1682e8f1ccf9"}}},{"cell_type":"code","source":["import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc505319-ba76-4df3-9bf6-ee5f7597e491"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Configure single-node training"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05d596a6-f16b-44cd-acc1-bfb20d2bc294"}}},{"cell_type":"code","source":["# Specify training parameters\nbatch_size = 100\nnum_epochs = 3\nmomentum = 0.5\nlog_interval = 100"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d009c6d-c001-4670-9e45-fe94f1bf19ac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def train_one_epoch(model, device, data_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(data_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(data_loader) * len(data),\n                100. * batch_idx / len(data_loader), loss.item()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b62afcd-6564-491a-8d3d-1139e5e1729d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Create methods for saving and loading model checkpoints"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8172e7a-f671-4232-91c7-a4c5459386f8"}}},{"cell_type":"code","source":["def save_checkpoint(log_dir, model, optimizer, epoch):\n  filepath = log_dir + '/checkpoint-{epoch}.pth.tar'.format(epoch=epoch)\n  state = {\n    'model': model.state_dict(),\n    'optimizer': optimizer.state_dict(),\n  }\n  torch.save(state, filepath)\n  \ndef load_checkpoint(log_dir, epoch=num_epochs):\n  filepath = log_dir + '/checkpoint-{epoch}.pth.tar'.format(epoch=epoch)\n  return torch.load(filepath)\n\ndef create_log_dir():\n  log_dir = os.path.join(PYTORCH_DIR, str(time()), 'MNISTDemo')\n  os.makedirs(log_dir)\n  return log_dir"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ee4f89d-352d-4fbb-9da4-b5037d5e2da7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Run single-node training with PyTorch"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3474cb1-f66e-4209-9723-e890b86229a7"}}},{"cell_type":"code","source":["import torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom time import time\nimport os\n\nsingle_node_log_dir = create_log_dir()\nprint(\"Log directory:\", single_node_log_dir)\n\ndef train(learning_rate):\n  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n  train_dataset = datasets.MNIST(\n    'data', \n    train=True,\n    download=True,\n    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n  data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n  model = Net().to(device)\n\n  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n\n  for epoch in range(1, num_epochs + 1):\n    train_one_epoch(model, device, data_loader, optimizer, epoch)\n    save_checkpoint(single_node_log_dir, model, optimizer, epoch)\n\n    \ndef test(log_dir):\n  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n  loaded_model = Net().to(device)\n  \n  checkpoint = load_checkpoint(log_dir)\n  loaded_model.load_state_dict(checkpoint['model'])\n  loaded_model.eval()\n\n  test_dataset = datasets.MNIST(\n    'data', \n    train=False,\n    download=True,\n    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n  data_loader = torch.utils.data.DataLoader(test_dataset)\n\n  test_loss = 0\n  for data, target in data_loader:\n      data, target = data.to(device), target.to(device)\n      output = loaded_model(data)\n      test_loss += F.nll_loss(output, target)\n  \n  test_loss /= len(data_loader.dataset)\n  print(\"Average test loss: {}\".format(test_loss.item()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dda0ed73-7dbb-44a5-bfc6-0afe8478d302"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Log directory: /dbfs/ml/horovod_pytorch/1613601002.1851563/MNISTDemo\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Log directory: /dbfs/ml/horovod_pytorch/1613601002.1851563/MNISTDemo\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Run the `train` function you just created to train a model on the driver node."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"834a844c-53e7-4e0b-95db-e2d37314810d"}}},{"cell_type":"code","source":["train(learning_rate = 0.001)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"080afc54-b5bd-4ce7-b50e-560231d88de7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/9912422 [00:00&lt;?, ?it/s]\r  0%|          | 49152/9912422 [00:00&lt;00:33, 295992.43it/s]\r  2%|▏         | 212992/9912422 [00:00&lt;00:25, 382174.85it/s]\r  9%|▉         | 876544/9912422 [00:00&lt;00:17, 527936.79it/s]\r 30%|███       | 3006464/9912422 [00:00&lt;00:09, 743770.35it/s]\r 58%|█████▊    | 5709824/9912422 [00:00&lt;00:04, 1046128.64it/s]\r 88%|████████▊ | 8683520/9912422 [00:01&lt;00:00, 1449510.09it/s]\r9920512it [00:01, 8483849.69it/s]                             \nExtracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/28881 [00:00&lt;?, ?it/s]\r32768it [00:00, 125974.40it/s]           \nExtracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/1648877 [00:00&lt;?, ?it/s]\r  1%|          | 16384/1648877 [00:00&lt;00:09, 163305.19it/s]\r  6%|▌         | 98304/1648877 [00:00&lt;00:07, 208219.52it/s]\r 22%|██▏       | 368640/1648877 [00:00&lt;00:04, 284999.76it/s]\r 30%|██▉       | 491520/1648877 [00:00&lt;00:03, 359526.53it/s]\r 44%|████▍     | 729088/1648877 [00:00&lt;00:01, 472628.96it/s]\r 59%|█████▊    | 966656/1648877 [00:00&lt;00:01, 606759.89it/s]\r 74%|███████▍  | 1220608/1648877 [00:01&lt;00:00, 759183.27it/s]\r 89%|████████▉ | 1474560/1648877 [00:01&lt;00:00, 956512.13it/s]\r1654784it [00:01, 1265048.28it/s]                            \nExtracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/4542 [00:00&lt;?, ?it/s]\r8192it [00:00, 73982.60it/s]            \nExtracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\nProcessing...\n/databricks/python/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\nDone!\n/local_disk0/tmp/1613600927050-0/PythonShell.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  # running &#39;import PythonShell&#39;\nTrain Epoch: 1 [0/60000 (0%)]\tLoss: 2.373813\nTrain Epoch: 1 [10000/60000 (17%)]\tLoss: 2.319232\nTrain Epoch: 1 [20000/60000 (33%)]\tLoss: 2.282479\nTrain Epoch: 1 [30000/60000 (50%)]\tLoss: 2.273975\nTrain Epoch: 1 [40000/60000 (67%)]\tLoss: 2.267378\nTrain Epoch: 1 [50000/60000 (83%)]\tLoss: 2.259475\nTrain Epoch: 2 [0/60000 (0%)]\tLoss: 2.209961\nTrain Epoch: 2 [10000/60000 (17%)]\tLoss: 2.251531\nTrain Epoch: 2 [20000/60000 (33%)]\tLoss: 2.189429\nTrain Epoch: 2 [30000/60000 (50%)]\tLoss: 2.155532\nTrain Epoch: 2 [40000/60000 (67%)]\tLoss: 2.087146\nTrain Epoch: 2 [50000/60000 (83%)]\tLoss: 2.048989\nTrain Epoch: 3 [0/60000 (0%)]\tLoss: 1.944567\nTrain Epoch: 3 [10000/60000 (17%)]\tLoss: 1.855910\nTrain Epoch: 3 [20000/60000 (33%)]\tLoss: 1.668793\nTrain Epoch: 3 [30000/60000 (50%)]\tLoss: 1.448902\nTrain Epoch: 3 [40000/60000 (67%)]\tLoss: 1.511713\nTrain Epoch: 3 [50000/60000 (83%)]\tLoss: 1.389288\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/9912422 [00:00&lt;?, ?it/s]\r  0%|          | 49152/9912422 [00:00&lt;00:33, 295992.43it/s]\r  2%|▏         | 212992/9912422 [00:00&lt;00:25, 382174.85it/s]\r  9%|▉         | 876544/9912422 [00:00&lt;00:17, 527936.79it/s]\r 30%|███       | 3006464/9912422 [00:00&lt;00:09, 743770.35it/s]\r 58%|█████▊    | 5709824/9912422 [00:00&lt;00:04, 1046128.64it/s]\r 88%|████████▊ | 8683520/9912422 [00:01&lt;00:00, 1449510.09it/s]\r9920512it [00:01, 8483849.69it/s]                             \nExtracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/28881 [00:00&lt;?, ?it/s]\r32768it [00:00, 125974.40it/s]           \nExtracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/1648877 [00:00&lt;?, ?it/s]\r  1%|          | 16384/1648877 [00:00&lt;00:09, 163305.19it/s]\r  6%|▌         | 98304/1648877 [00:00&lt;00:07, 208219.52it/s]\r 22%|██▏       | 368640/1648877 [00:00&lt;00:04, 284999.76it/s]\r 30%|██▉       | 491520/1648877 [00:00&lt;00:03, 359526.53it/s]\r 44%|████▍     | 729088/1648877 [00:00&lt;00:01, 472628.96it/s]\r 59%|█████▊    | 966656/1648877 [00:00&lt;00:01, 606759.89it/s]\r 74%|███████▍  | 1220608/1648877 [00:01&lt;00:00, 759183.27it/s]\r 89%|████████▉ | 1474560/1648877 [00:01&lt;00:00, 956512.13it/s]\r1654784it [00:01, 1265048.28it/s]                            \nExtracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n\r0it [00:00, ?it/s]\r  0%|          | 0/4542 [00:00&lt;?, ?it/s]\r8192it [00:00, 73982.60it/s]            \nExtracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\nProcessing...\n/databricks/python/lib/python3.7/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\nDone!\n/local_disk0/tmp/1613600927050-0/PythonShell.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  # running &#39;import PythonShell&#39;\nTrain Epoch: 1 [0/60000 (0%)]\tLoss: 2.373813\nTrain Epoch: 1 [10000/60000 (17%)]\tLoss: 2.319232\nTrain Epoch: 1 [20000/60000 (33%)]\tLoss: 2.282479\nTrain Epoch: 1 [30000/60000 (50%)]\tLoss: 2.273975\nTrain Epoch: 1 [40000/60000 (67%)]\tLoss: 2.267378\nTrain Epoch: 1 [50000/60000 (83%)]\tLoss: 2.259475\nTrain Epoch: 2 [0/60000 (0%)]\tLoss: 2.209961\nTrain Epoch: 2 [10000/60000 (17%)]\tLoss: 2.251531\nTrain Epoch: 2 [20000/60000 (33%)]\tLoss: 2.189429\nTrain Epoch: 2 [30000/60000 (50%)]\tLoss: 2.155532\nTrain Epoch: 2 [40000/60000 (67%)]\tLoss: 2.087146\nTrain Epoch: 2 [50000/60000 (83%)]\tLoss: 2.048989\nTrain Epoch: 3 [0/60000 (0%)]\tLoss: 1.944567\nTrain Epoch: 3 [10000/60000 (17%)]\tLoss: 1.855910\nTrain Epoch: 3 [20000/60000 (33%)]\tLoss: 1.668793\nTrain Epoch: 3 [30000/60000 (50%)]\tLoss: 1.448902\nTrain Epoch: 3 [40000/60000 (67%)]\tLoss: 1.511713\nTrain Epoch: 3 [50000/60000 (83%)]\tLoss: 1.389288\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Load and use the model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5230f619-a5ff-44df-baa5-b3f1ec88015a"}}},{"cell_type":"code","source":["test(single_node_log_dir)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5641d0a-e650-4ab6-b721-6f3d49ba81c7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/local_disk0/tmp/1613600927050-0/PythonShell.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  # running &#39;import PythonShell&#39;\nAverage test loss: 0.9279822111129761\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1613600927050-0/PythonShell.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  # running &#39;import PythonShell&#39;\nAverage test loss: 0.9279822111129761\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Migrate to HorovodRunner\n\nHorovodRunner takes a Python method that contains deep learning training code with Horovod hooks. HorovodRunner pickles the method on the driver and distributes it to Spark workers. A Horovod MPI job is embedded as a Spark job using barrier execution mode."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f960dc9e-295f-47df-bb94-237ff2fe8428"}}},{"cell_type":"code","source":["import horovod.torch as hvd\nfrom sparkdl import HorovodRunner"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3110497-edcb-400a-a35b-f5cf0f09310c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["hvd_log_dir = create_log_dir()\nprint(\"Log directory:\", hvd_log_dir)\n\ndef train_hvd(learning_rate):\n  \n  # Initialize Horovod\n  hvd.init()  \n  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n  \n  if device.type == 'cuda':\n    # Pin GPU to local rank\n    torch.cuda.set_device(hvd.local_rank())\n\n  train_dataset = datasets.MNIST(\n    # Use different root directory for each worker to avoid conflicts\n    root='data-%d'% hvd.rank(),  \n    train=True, \n    download=True,\n    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n  )\n\n  from torch.utils.data.distributed import DistributedSampler\n  \n  # Configure the sampler so that each worker gets a distinct sample of the input dataset\n  train_sampler = DistributedSampler(train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n  # Use train_sampler to load a different sample of data on each worker\n  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n\n  model = Net().to(device)\n  \n  # The effective batch size in synchronous distributed training is scaled by the number of workers\n  # Increase learning_rate to compensate for the increased batch size\n  optimizer = optim.SGD(model.parameters(), lr=learning_rate * hvd.size(), momentum=momentum)\n\n  # Wrap the local optimizer with hvd.DistributedOptimizer so that Horovod handles the distributed optimization\n  optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\n  \n  # Broadcast initial parameters so all workers start with the same parameters\n  hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n\n  for epoch in range(1, num_epochs + 1):\n    train_one_epoch(model, device, train_loader, optimizer, epoch)\n    # Save checkpoints only on worker 0 to prevent conflicts between workers\n    if hvd.rank() == 0:\n      save_checkpoint(hvd_log_dir, model, optimizer, epoch)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3fdd85b-c362-4853-a8b0-9bfa07e270ef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Log directory: /dbfs/ml/horovod_pytorch/1613601232.8936656/MNISTDemo\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Log directory: /dbfs/ml/horovod_pytorch/1613601232.8936656/MNISTDemo\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now that you have defined a training function with Horovod,  you can use HorovodRunner to distribute the work of training the model. \n\nThe HorovodRunner parameter `np` sets the number of processes. This example uses a cluster with two workers, each with a single GPU, so set `np=2`. (If you use `np=-1`, HorovodRunner trains using a single process on the driver node.)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"231b795c-7e75-44c9-aa78-e9eaf4cdbd04"}}},{"cell_type":"code","source":["hr = HorovodRunner(np=2) \nhr.run(train_hvd, learning_rate = 0.001)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d994b687-b14b-43c0-bd28-2397a4c4a90d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">HorovodRunner will only stream logs generated by :func:`sparkdl.horovod.log_to_driver` or\n:class:`sparkdl.horovod.tensorflow.keras.LogCallback` to notebook cell output. If want to stream all\nlogs to driver for debugging, you can set driver_log_verbosity to &#39;log_callback_only&#39;, like\n`HorovodRunner(np=2, driver_log_verbosity=&#39;all&#39;)`.\nThe global names read or written to by the pickled function are {&#39;range&#39;, &#39;hvd&#39;, &#39;datasets&#39;, &#39;batch_size&#39;, &#39;num_epochs&#39;, &#39;Net&#39;, &#39;momentum&#39;, &#39;save_checkpoint&#39;, &#39;torch&#39;, &#39;transforms&#39;, &#39;optim&#39;, &#39;hvd_log_dir&#39;, &#39;train_one_epoch&#39;}.\nThe pickled object size is 4501 bytes.\n\n### How to enable Horovod Timeline? ###\nHorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To\nrecord a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the\ntimeline file to be created. You can then open the timeline file  using the chrome://tracing\nfacility of the Chrome browser.\n\nStart training.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">HorovodRunner will only stream logs generated by :func:`sparkdl.horovod.log_to_driver` or\n:class:`sparkdl.horovod.tensorflow.keras.LogCallback` to notebook cell output. If want to stream all\nlogs to driver for debugging, you can set driver_log_verbosity to &#39;log_callback_only&#39;, like\n`HorovodRunner(np=2, driver_log_verbosity=&#39;all&#39;)`.\nThe global names read or written to by the pickled function are {&#39;range&#39;, &#39;hvd&#39;, &#39;datasets&#39;, &#39;batch_size&#39;, &#39;num_epochs&#39;, &#39;Net&#39;, &#39;momentum&#39;, &#39;save_checkpoint&#39;, &#39;torch&#39;, &#39;transforms&#39;, &#39;optim&#39;, &#39;hvd_log_dir&#39;, &#39;train_one_epoch&#39;}.\nThe pickled object size is 4501 bytes.\n\n### How to enable Horovod Timeline? ###\nHorovodRunner has the ability to record the timeline of its activity with Horovod  Timeline. To\nrecord a Horovod Timeline, set the `HOROVOD_TIMELINE` environment variable  to the location of the\ntimeline file to be created. You can then open the timeline file  using the chrome://tracing\nfacility of the Chrome browser.\n\nStart training.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["test(hvd_log_dir)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca15511e-7c1a-4a06-bd20-e0364243bd26"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/local_disk0/tmp/1613600927050-0/PythonShell.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  # running &#39;import PythonShell&#39;\nAverage test loss: 0.6572399735450745\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1613600927050-0/PythonShell.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n  # running &#39;import PythonShell&#39;\nAverage test loss: 0.6572399735450745\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Under the hood, HorovodRunner takes a Python method that contains deep learning training code with Horovod hooks. HorovodRunner pickles the method on the driver and distributes it to Spark workers. A Horovod MPI job is embedded as a Spark job using the barrier execution mode. The first executor collects the IP addresses of all task executors using BarrierTaskContext and triggers a Horovod job using `mpirun`. Each Python MPI process loads the pickled user program, deserializes it, and runs it.\n\nFor more information, see [HorovodRunner API documentation](https://databricks.github.io/spark-deep-learning/#api-documentation)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4149a68f-2901-48ab-b809-45aadfec0183"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PyTorchDistributedDeepLearningTraining","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3017985469288649}},"nbformat":4,"nbformat_minor":0}
